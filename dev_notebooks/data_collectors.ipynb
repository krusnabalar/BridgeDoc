{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "pd.set_option('display.width', 5000)"
      ],
      "metadata": {
        "id": "OGsOT9SOirvH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def daterange(start_date, end_date):\n",
        "  for day in range(int((end_date - start_date).days)):\n",
        "    yield start_date + timedelta(day)\n",
        "\n",
        "def timerange(start_time, end_time):\n",
        "  for time_step in range(int((end_time - start_time).days*2)):\n",
        "    yield start_time + timedelta(hours=12*time_step)"
      ],
      "metadata": {
        "id": "IFkZlaT2kCqp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity checks for the endpoints\n",
        "test_request = requests.get('https://api.pushshift.io/reddit/search/submission', params={'q':'hurts',\n",
        "                                                                                         'sort':'desc', \n",
        "                                                                                         'sort_type': 'score',\n",
        "                                                                                         'size':10, \n",
        "                                                                                         'metadata':'true',\n",
        "                                                                                         'subreddit': 'askdocs',\n",
        "                                                                                         'fields': ['title', 'selftext', 'subreddit', 'score', 'upvote_ratio',\n",
        "                                                                                                    'total_awards_received', 'full_link', 'link_flair_text', \n",
        "                                                                                                    'author', 'id', 'permalink', 'url', 'num_comments']})\n",
        "test_json = test_request.json()\n",
        "test_request"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcgwdxQqtqKK",
        "outputId": "4c0c027e-2829-4d44-909c-4b5036e92441"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Submissions endpoint\n",
        "responses_df = pd.DataFrame(columns=['title', 'selftext', 'subreddit', 'score', 'upvote_ratio', 'total_awards_received', 'full_link', 'link_flair_text', 'author', 'id', 'permalink', 'url', 'num_comments'])\n",
        "submission_endpoint = 'https://api.pushshift.io/reddit/search/submission'\n",
        "\n",
        "params = {\n",
        "    'q':'',\n",
        "    'sort':'desc',\n",
        "    'sort_type':'score',\n",
        "    'size':100,\n",
        "    'after':None,\n",
        "    'before':None,\n",
        "    'metadata':'true',\n",
        "    'fields': ['title', 'selftext', 'subreddit', 'score', 'upvote_ratio', 'total_awards_received', \n",
        "               'full_link', 'link_flair_text', 'author', 'id', 'permalink', 'url', 'num_comments']\n",
        "}"
      ],
      "metadata": {
        "id": "Um4_QoGrj5E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24h collection\n",
        "start_date, end_date = datetime(2022, 9, 23, 0, 0), datetime(2022, 9, 30, 0, 0)\n",
        "for date in daterange(start_date, end_date):\n",
        "  params['after'], params['before'] = date, date + timedelta(days=1)\n",
        "\n",
        "  response = requests.get(submission_endpoint, params=params)\n",
        "  data, metadata = response.json()['data'], response.json()['metadata']\n",
        "  if not data:\n",
        "    print(date.date(), 'empty')\n",
        "  else:\n",
        "    print(date.date(), metadata['size'], metadata['shards'], metadata['timed_out'], metadata['size'])\n",
        "  \n",
        "  [item.update({'date': date.date()}) for item in data]\n",
        "  responses_df = responses_df.append(data, ignore_index=True)\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "#save_to_csv\n",
        "responses_df.to_csv('file_name_submissions.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s7LUYmuj7Ga",
        "outputId": "221d184b-4b5a-47be-de45-81428212a07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-23 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-24 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-25 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-26 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-27 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-28 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n",
            "2022-09-29 100 {'failed': 0, 'skipped': 0, 'successful': 4, 'total': 4} False 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comments endpoint\n",
        "responses_comments_df = pd.DataFrame(columns=['author', 'body', 'id', 'link_id', 'permalink', 'score', 'subreddit', 'is_submitter', 'total_awards_received'])\n",
        "comment_endpoint = 'https://api.pushshift.io/reddit/search/comment'\n",
        "\n",
        "params = {\n",
        "    'q':'',\n",
        "    'sort':'desc',\n",
        "    'sort_type':'score',\n",
        "    'size':100,\n",
        "    'after':None,\n",
        "    'before':None,\n",
        "    'metadata':'true',\n",
        "    'fields': ['author', 'body', 'id', 'link_id', 'permalink', 'score', 'subreddit', 'is_submitter', 'total_awards_received']\n",
        "}"
      ],
      "metadata": {
        "id": "3fmxw4QYx--6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24h collection\n",
        "start_date, end_date = datetime(2017, 10, 9, 0, 0), datetime(2017, 10, 16, 0, 0)\n",
        "for date in daterange(start_date, end_date):\n",
        "  params['after'], params['before'] = date, date + timedelta(days=1)\n",
        "\n",
        "  response = requests.get(comment_endpoint, params=params)\n",
        "  data, metadata = response.json()['data'], response.json()['metadata']\n",
        "  if not data:\n",
        "    print(date, 'empty')\n",
        "  else:\n",
        "    print(date, metadata['size'], metadata['shards'], metadata['timed_out'], metadata['size'])\n",
        "  \n",
        "  [item.update({'date': date.date()}) for item in data]\n",
        "  responses_comments_df = responses_comments_df.append(data, ignore_index=True)\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "#save to csv\n",
        "responses_comments_df.to_csv('file_name_submissions_comments.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5lH1TP5yhdB",
        "outputId": "7e2c9256-cf52-4994-a94b-c433942bbb03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017-10-09 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-10 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-11 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-12 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-13 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-14 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n",
            "2017-10-15 00:00:00 100 {'failed': 0, 'skipped': 0, 'successful': 67, 'total': 74} False 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtP46d2bzYps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}